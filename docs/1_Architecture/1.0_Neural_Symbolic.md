# Neural-Symbolic Architecture

> **Trinity's 5-layer self-healing pipeline**

Trinity implements a unique **neural-symbolic architecture** that combines deterministic rule-based systems with machine learning models to create an intelligent, self-healing static site generator.

---

## Architecture Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                  TRINITY v0.8.0 (PHASE 6)                  │
└─────────────────────────────────────────────────────────────────┘

┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│   SKELETON   │    │     BRAIN    │    │  PREDICTOR   │
│              │    │              │    │              │
│  Jinja2 +    │───▶│  Local LLM   │───▶│ Random Forest│
│  Tailwind    │    │  (Async)     │    │ (Multiclass) │
│              │    │              │    │              │
│ Deterministic│    │   Creative   │    │  Predictive  │
└──────────────┘    └──────────────┘    └──────────────┘
        │                   │                    │
        │                   ▼                    ▼
        │            ┌──────────────┐    ┌──────────────┐
        │            │    CACHE     │    │    HEALER    │
        │            │              │    │              │
        │            │  Memory/     │    │  LSTM Neural │
        │            │  Redis/      │    │  + Heuristic │
        │            │  Filesystem  │    │              │
        │            └──────────────┘    └──────────────┘
        │                                        │
        │                                        ▼
        │                                 ┌──────────────┐
        │                                 │   GUARDIAN   │
        │                                 │  (Optional)  │
        └────────────────────────────────▶│  Playwright  │
                                          │  Visual QA   │
                                          └──────────────┘
```

**Key Principles:**
1. **Separation of Concerns**: Each layer has a single responsibility
2. **Fail-Safe Defaults**: Graceful degradation at every layer
3. **Observable**: Structured logging throughout
4. **Testable**: Each component can be tested in isolation
5. **Async-First**: Non-blocking I/O for 6x throughput

---

## Layer 1: Brain (Content Generation)

**Responsibility:** Generate compelling content from structured input

### AsyncLLMClient

The async LLM client provides high-throughput content generation with production-grade reliability:

**Features:**
- HTTP/2 multiplexing for concurrent requests
- Exponential backoff retry logic (max 3 attempts)
- Circuit breaker integration (fail-fast after 5 errors)
- Multi-tier cache support (memory/Redis/filesystem)
- Structured logging with correlation IDs

**Performance:**
- **Throughput**: 30 req/sec (async) vs 5 req/sec (sync) - **6x improvement**
- **Latency**: 200-500ms (cached), 2-5s (LLM call)
- **Cost**: $0.002-0.01 per request (cloud LLMs), $0 (local)
- **Cache Hit Rate**: 60% in production

### Supported LLM Providers

| Provider | Local/Cloud | Speed | Cost | Best For |
|----------|-------------|-------|------|----------|
| **Ollama** | Local | Fast | Free | Development, privacy |
| **LlamaCPP** | Local | Fast | Free | Custom models |
| **OpenAI** | Cloud | Medium | $$$ | Production quality |
| **Claude** | Cloud | Medium | $$ | Long context |
| **Gemini** | Cloud | Fast | $ | Fast iteration |

### Content Generation Flow

```python
# 1. Load input data
content = ContentLoader.load("data/portfolio.txt")

# 2. Build theme-aware prompt
prompt = PromptBuilder.build(
    content=content,
    theme="brutalist",
    schema=PortfolioSchema
)

# 3. Generate with LLM (async)
async with AsyncLLMClient() as client:
    response = await client.generate(
        prompt,
        correlation_id="build-123"
    )

# 4. Validate against schema
validated = PortfolioSchema.parse_obj(response)

# 5. Cache for future builds
cache.set(cache_key, validated, ttl=3600)
```

---

## Layer 2: Skeleton (Theme Application)

**Responsibility:** Apply professional themes to generated content

### YAML Theme System (v0.6.0)

Trinity uses YAML configuration for better developer experience:

```yaml
# config/themes.yaml
enterprise:
  description: "Corporate, clean, trustworthy design"
  category: business
  color_palette:
    primary: "blue"
    secondary: "gray"
    accent: "indigo"
  typography:
    heading: "font-bold"
    body: "font-normal"
  use_case: "Professional portfolios, corporate sites"
  classes:
    hero_title: "text-5xl font-bold text-blue-900"
    hero_subtitle: "text-xl text-gray-600"
    card: "bg-white rounded-lg shadow-md p-6"
    # ... 50+ Tailwind class mappings
```

### Built-in Themes

**14 production-ready themes across 5 categories:**

1. **Business**: Enterprise, Minimalist
2. **Technical**: Hacker, Tech_01, Tech_02
3. **Creative**: Brutalist, Editorial, Graffiti, Neon
4. **Retro**: Retro Arcade, Vintage, Y2K
5. **Minimal**: Clean, Zen

### Rendering Pipeline

```python
# 1. Load theme configuration
theme = ThemeLoader.load("brutalist")

# 2. Prepare template context
context = {
    "content": validated_content,
    "theme": theme.classes,
    "metadata": theme.metadata,
    "dark_mode": True
}

# 3. Render Jinja2 template
template = jinja_env.get_template("portfolio.html.j2")
html = template.render(context)

# 4. Inject Tailwind CSS
html_with_css = TailwindProcessor.process(html)
```

---

## Layer 3: Predictor (ML Risk Assessment)

**Responsibility:** Predict best healing strategy **before** rendering

### Why Prediction?

Traditional approach: Build → Test → Fix → Rebuild (slow, expensive)

Trinity approach: **Predict strategy → Pre-heal → Skip Guardian if safe** (fast, smart)

### Model Architecture

**Random Forest Classifier (Multiclass):**
- 100 estimators
- Max depth: 10
- Training data: 1000+ real build events
- Features: 7 key metrics (content + theme + CSS density)
- Output: Strategy ID (0-4)

### Feature Engineering

```python
features = [
    "input_char_len",           # Total characters
    "input_word_count",         # Word count
    "css_density_spacing",      # Count of spacing classes
    "css_density_layout",       # Count of layout classes
    "pathological_score",       # Risk score for pathological strings
    "theme_encoded",            # Encoded theme ID
    "active_strategy_encoded"   # Current strategy ID
]
```

### Prediction Flow

```python
# 1. Extract features
features = FeatureExtractor.extract(content, theme)

# 2. Load trained model
model = joblib.load("models/layout_risk_predictor.pkl")

# 3. Predict best strategy
prediction = model.predict_best_strategy(features)
# Returns: {
#   "strategy_id": 2,
#   "strategy_name": "FONT_SHRINK",
#   "confidence": 0.85
# }

# 4. Apply strategy immediately
if prediction["strategy_id"] > 0:
    logger.info(f"Pre-healing with {prediction['strategy_name']}")
    content = apply_strategy(content, prediction["strategy_id"])
```

### Model Performance

- **Accuracy**: 87% on test set
- **Precision**: 82% (few false positives)
- **Recall**: 91% (catches most issues)
- **F1 Score**: 0.86
- **Inference Time**: <10ms per prediction

**Impact:** Reduces Guardian usage by 60%, saving ~2-3 seconds per build on low-risk content.

---

## Layer 4: Healer (CSS Auto-Repair)

**Responsibility:** Automatically fix layout issues detected or predicted

### Hybrid Architecture

Trinity uses a **hybrid healing approach** combining neural and symbolic methods:

#### Neural Healer (LSTM Seq2Seq)

**Architecture:**
- 270K parameters
- 2 LSTM layers × 128 hidden dimensions
- Trained on 5000+ CSS fix pairs
- Context-aware Tailwind class generation

**Model Structure:**
```
Encoder (Problem Context):
  Input: [theme, error_type, content_length] (embedded)
  LSTM: 2 layers × 128 hidden dim
  Output: Context vector (128 dim)

Decoder (Fix Generation):
  Input: Context vector + previous token
  LSTM: 2 layers × 128 hidden dim
  Attention: Context + decoder state
  Output: Token predictions (Tailwind classes)
```

**Performance:**
- Fix success rate: 78% (first attempt)
- Generation time: 50-100ms
- Fallback to SmartHealer if confidence < 0.6

#### SmartHealer (Heuristic Fallback)

**When Used:**
- Neural model unavailable (CI/CD, minimal installs)
- Neural model low confidence (<0.6)
- Guaranteed deterministic fixes needed

**Strategies:**

**Strategy 1: CSS_BREAK_WORD**
```css
/* Problem: Long unbreakable words overflow */
.title {
  overflow: hidden;  /* ❌ Text cut off */
}

/* Fix: Add word breaking */
.title {
  word-break: break-word;
  overflow-wrap: break-word;
}
```

**Strategy 2: FONT_SHRINK**
```css
/* Problem: Text too large for container */
.card-title {
  font-size: 2rem;  /* ❌ Overflows */
}

/* Fix: Reduce font size */
.card-title {
  font-size: 1.5rem;  /* ✅ Fits */
}
```

**Strategy 3: CONTAINER_EXPAND**
```css
/* Problem: Fixed width too narrow */
.card {
  width: 300px;  /* ❌ Content doesn't fit */
}

/* Fix: Use min-width */
.card {
  min-width: 300px;
  width: auto;  /* ✅ Expands as needed */
}
```

**Strategy 4: TRUNCATE**
```css
/* Problem: Text should be single-line */
.subtitle {
  /* ❌ Wraps to multiple lines */
}

/* Fix: Ellipsis truncation */
.subtitle {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}
```

### Healing Pipeline

```python
# 1. Guardian detects overflow
error = {
    "type": "text_overflow",
    "element": ".card-title",
    "content_length": 87,
    "container_width": 250
}

# 2. Try neural healer first
if neural_available and confidence > 0.6:
    fix = NeuralHealer.generate_fix(error, theme)
    logger.info("Neural fix applied", extra={
        "strategy": "neural",
        "confidence": confidence
    })
else:
    # 3. Fallback to heuristic
    fix = SmartHealer.select_strategy(error)
    logger.info("Heuristic fix applied", extra={
        "strategy": fix.strategy
    })

# 4. Apply fix and rebuild
html_fixed = apply_css_fix(html, fix)

# 5. Validate fix worked
if Guardian.validate(html_fixed):
    logger.info("Fix successful")
else:
    logger.warning("Fix failed, trying next strategy")
```

---

## Layer 5: Guardian (Visual Validation)

**Responsibility:** Verify layout integrity using browser automation

### Playwright Integration

**Features:**
- Headless Chromium testing
- Visual regression detection
- Responsive viewport testing
- Screenshot comparison
- Overflow detection

**Performance:**
- **Validation time**: 2-3 seconds per page
- **Accuracy**: 95% detection rate
- **False positives**: <5% (tuned thresholds)

### Detection Algorithm

```python
async def detect_overflows(page: Page) -> List[OverflowError]:
    """Detect text overflow in rendered page"""
    
    # 1. Find all text elements
    elements = await page.query_selector_all("h1, h2, p, span")
    
    overflows = []
    for el in elements:
        # 2. Get element dimensions
        box = await el.bounding_box()
        scroll_width = await el.evaluate("el => el.scrollWidth")
        
        # 3. Check for overflow
        if scroll_width > box["width"] + 5:  # 5px tolerance
            overflows.append({
                "element": await el.evaluate("el => el.className"),
                "overflow": scroll_width - box["width"],
                "text": await el.text_content()
            })
    
    return overflows
```

### Usage Modes

**Mode 1: Always On (Development)**
```python
# Validate every build
python main.py --theme brutalist --guardian
```

**Mode 2: Risk-Based (Production)**
```python
# Only validate high-risk builds
if predictor.risk_score > 0.7:
    enable_guardian = True
```

**Mode 3: Disabled (CI/CD)**
```python
# Skip visual validation for speed
python main.py --no-guardian
```

---

## Infrastructure Components

### Multi-Tier Caching (v0.6.0)

**3-tier cache architecture** for 40% cost reduction:

**Tier 1: Memory Cache**
- In-process LRU cache
- 100 entries max
- <1ms access time
- Cleared on restart

**Tier 2: Redis Cache (Optional)**
- Distributed caching
- 3600s TTL
- 5-10ms access time
- Shared across processes

**Tier 3: Filesystem Cache**
- Persistent local cache
- `.cache/` directory
- 20-50ms access time
- Survives restarts

**Configuration:**
```yaml
# config/settings.yaml
cache:
  enabled: true
  tiers:
    - memory    # Always enabled
    - redis     # Optional (requires Redis server)
    - filesystem  # Always enabled
  redis:
    host: localhost
    port: 6379
    db: 0
  ttl: 3600  # 1 hour
```

### Structured Logging (v0.6.0)

**JSON logging for observability:**

```python
# Usage
logger = get_logger(__name__)

logger.info("LLM request started", extra={
    "provider": "ollama",
    "model": "llama3.2",
    "prompt_length": 512,
    "correlation_id": "build-123"
})

# Output (JSON)
{
  "timestamp": "2025-01-15T10:30:45.123Z",
  "level": "INFO",
  "logger": "trinity.llm_client",
  "message": "LLM request started",
  "provider": "ollama",
  "model": "llama3.2",
  "prompt_length": 512,
  "correlation_id": "build-123"
}
```

**Log Aggregation Ready:**
- ELK Stack (Elasticsearch, Logstash, Kibana)
- Datadog
- AWS CloudWatch
- Grafana Loki

**Makefile Commands:**
```bash
make logs              # View all logs (human-readable)
make logs-json         # View all logs (JSON)
make logs-errors       # View only errors
make logs-performance  # View performance metrics
make logs-analyze      # Analyze with jq
```

### Circuit Breaker

**Fail-fast on repeated errors:**

```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    async def call(self, func, *args, **kwargs):
        if self.state == "OPEN":
            if time.time() - self.last_failure < self.timeout:
                raise CircuitBreakerOpen("Too many failures")
            else:
                self.state = "HALF_OPEN"
        
        try:
            result = await func(*args, **kwargs)
            self.reset()
            return result
        except Exception as e:
            self.record_failure()
            raise
```

**States:**
- **CLOSED**: Normal operation
- **OPEN**: Failing fast (timeout period)
- **HALF_OPEN**: Testing if service recovered

---

## Data Flow

### Complete Build Pipeline

```
1. Input
   ↓
   data/portfolio.txt (raw content)
   
2. Brain (Content Generation)
   ↓
   AsyncLLMClient → LLM API → JSON response
   ↓
   Pydantic validation → structured content
   ↓
   CacheManager → store in cache
   
3. Skeleton (Theme Application)
   ↓
   Load YAML theme → Jinja2 rendering
   ↓
   HTML + Tailwind CSS
   
4. Predictor (Risk Assessment)
   ↓
   FeatureExtractor → 15 features
   ↓
   Random Forest → risk_score (0.0-1.0)
   ↓
   Decision: Guardian needed?
   
5a. Low Risk (score < 0.4)
   ↓
   Save HTML → output/index.html
   ↓
   Done! (2-3 seconds)

5b. High Risk (score > 0.7)
   ↓
   Guardian validation → detect overflows
   ↓
   If broken: Healer → apply fix
   ↓
   Rebuild → validate again
   ↓
   Save HTML → output/index.html
   ↓
   Done! (5-8 seconds)
```

---

## Performance Characteristics

### Phase 6 Improvements (v0.7.0 → v0.8.0)

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **LLM Throughput** | 5 req/sec | 30 req/sec | **6x faster** |
| **Build Time (cached)** | 3-5s | 0.5-1s | **5x faster** |
| **LLM Cost** | $0.01/build | $0.006/build | **40% reduction** |
| **Guardian Usage** | 100% | 40% | **60% reduction** |
| **Log Parsing** | grep | jq (JSON) | **Queryable** |
| **Prediction** | Binary Risk | Multiclass Strategy | **Smarter** |

### Timing Breakdown (Typical Build)

```
Total: 2.8 seconds

Content Generation:  1.2s (43%)
├─ LLM request:     0.8s
├─ Cache check:     0.1s
└─ Validation:      0.3s

Theme Rendering:     0.3s (11%)
├─ Template load:   0.1s
└─ Jinja2 render:   0.2s

Risk Prediction:     0.01s (<1%)
└─ Strategy Selection: <1ms

Guardian (if needed): 2.5s (optional)
├─ Browser launch:  1.0s
├─ Page load:       0.8s
└─ Validation:      0.7s

Healer (if broken):  0.15s (optional)
├─ Neural model:    0.08s
└─ CSS application: 0.07s
```

**Optimization Focus:**
- LLM requests (async + caching)
- Guardian usage (risk-based)
- Browser overhead (reuse instances)

---

## Vision: Transfer Learning & Centuria Factory

### Current Status (v0.7.0)

**What's Complete:**
✅ Random Forest predictor (87% accuracy)
✅ LSTM neural healer (270K params, 78% success rate)
✅ Centuria Factory infrastructure (theme generation)
✅ 14 production themes (5 categories)

**What's Pending:**
⏳ Large-scale training dataset (100+ themes)
⏳ Transfer learning benefits (universal layout rules)

### The Vision: From Theme Patterns to DOM Physics

**Traditional Approach:**
```
Model learns: "Brutalist theme + long title = overflow"
Problem: Doesn't generalize to new themes
```

**Centuria Factory Approach:**
```
Model learns: "Any theme + text width > container = overflow"
Breakthrough: Universal layout rules, not theme-specific patterns
```

**How It Works:**

1. **Generate 100+ Diverse Themes**
   - Centuria Factory creates themes with random:
     - Color palettes
     - Typography scales
     - Layout densities
     - Container widths
   - Forces model to ignore theme aesthetics

2. **Train on Universal Features**
   - Content length vs container width
   - Font size vs available space
   - Text flow vs layout constraints
   - **Result:** Model learns DOM physics, not theme quirks

3. **Transfer to Production**
   - Model works on ANY theme (even unseen ones)
   - Generalizes beyond training data
   - Predicts issues before rendering

**Current Dataset:**
- 15 themes, 182 training samples
- Limited to known theme patterns

**Target Dataset (Pending):**
- 100+ themes, 10,000+ training samples
- Universal layout rule learning
- True transfer learning capability

---

## Next Steps

See [Async & MLOps](./1.1_Async_MLOps.md) for Phase 6 implementation details.

See [Development → Setup](../2_Development/2.0_Setup.md) for installation and usage.

See [Features](../3_Features/) for self-healing and Centuria Factory guides.
